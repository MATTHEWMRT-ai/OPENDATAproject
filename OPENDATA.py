import streamlit as st
from streamlit_folium import st_folium
import folium
from folium.plugins import HeatMap
import requests
import pandas as pd
import altair as alt

# ==========================================
# 0. CONFIGURATION PAGE
# ==========================================
st.set_page_config(
    page_title="City Pulse Dynamic", 
    page_icon="üåç", 
    layout="wide", 
    initial_sidebar_state="expanded"
)

# ==========================================
# 1. INTELLIGENCE (Classification & Heuristiques)
# ==========================================

# Mots-cl√©s pour classer les datasets
CATEGORIES_RULES = {
    "üö≤ Mobilit√©": ["velo", "cyclab", "bicloo", "trottinette", "stationnement", "parking", "metro", "bus", "tram", "transport", "gare", "pieton", "sncf"],
    "üé≠ Culture & Sorties": ["cinema", "theatre", "musee", "culture", "bibliotheque", "exposition", "agenda", "evenement", "patrimoine", "concert", "visite"],
    "üå≥ Nature & Cadre de vie": ["jardin", "parc", "arbre", "eau", "fontaine", "dechet", "proprete", "tri", "banc", "toilette", "caniparc", "vert"],
    "üè´ Services Publics": ["ecole", "creche", "college", "lycee", "administration", "public", "mairie", "vote", "election", "citoyen", "organisme"],
    "üè• Sant√© & Social": ["sante", "hopital", "medecin", "pharmacie", "defibrillateur", "social", "handicap", "accessibilite", "urgence", "aide"]
}

# Mapping Mots-cl√©s -> Ic√¥nes FontAwesome & Couleurs
ICON_RULES = [
    (["parking", "stationnement"], "parking", "blue"),
    (["velo", "cycliste", "bicloo", "piste"], "bicycle", "red"),
    (["bus", "tram", "metro", "transport", "tan", "star"], "bus", "cadetblue"),
    (["parc", "jardin", "arbre", "square"], "tree", "green"),
    (["eau", "fontaine", "piscine"], "tint", "lightblue"),
    (["toilette", "sanisette", "wc"], "venus-mars", "gray"),
    (["wifi", "internet", "numerique"], "wifi", "purple"),
    (["musee", "art", "culture", "biblio"], "paint-brush", "orange"),
    (["ecole", "college", "enseignement", "scolaire"], "graduation-cap", "pink"),
    (["sante", "defibrillateur", "hopital", "secours"], "heartbeat", "darkred"),
    (["poubelle", "dechet", "tri", "verre"], "trash", "darkgreen"),
]

def detecter_style(texte_analyse):
    """Devine l'ic√¥ne et la couleur bas√©es sur le texte"""
    texte = texte_analyse.lower()
    for mots_cles, icone, couleur in ICON_RULES:
        if any(mot in texte for mot in mots_cles):
            return icone, couleur
    return "map-marker", "blue"

def detecter_categorie(texte_analyse):
    """Devine la cat√©gorie"""
    texte = texte_analyse.lower()
    for cat, mots in CATEGORIES_RULES.items():
        if any(mot in texte for mot in mots):
            return cat
    return "üìÇ Divers / Autres"

def analyser_structure_dataset(dataset_item):
    """
    Analyse les champs pour trouver Titre, Adresse et G√©olocalisation.
    """
    fields = dataset_item.get("fields", [])
    field_names = [f["name"] for f in fields]
    
    # 1. V√©rification G√©olocalisation (Indispensable pour la carte)
    col_geo = None
    # Priorit√© 1 : Champ type geo_point_2d
    for f in fields:
        if f["type"] == "geo_point_2d":
            col_geo = f["name"]
            break
    
    # Priorit√© 2 : Recherche lat/lon explicites
    if not col_geo:
        has_lat = any(x in field_names for x in ["lat", "latitude", "y_wgs84"])
        has_lon = any(x in field_names for x in ["lon", "long", "longitude", "x_wgs84"])
        if has_lat and has_lon:
            col_geo = "AUTO_DETECT_LAT_LON"
            
    if not col_geo:
        return None # On ignore ce dataset s'il n'a pas de coordonn√©es

    # 2. D√©tection Titre
    col_titre = None
    scores_titre = ["nom", "titre", "libelle", "intitule", "name", "label", "id", "identifiant"]
    for candidat in scores_titre:
        found = [n for n in field_names if candidat in n.lower()]
        if found:
            col_titre = found[0]
            break
    if not col_titre and field_names: col_titre = field_names[0]

    # 3. D√©tection Adresse
    col_adresse = None
    scores_adresse = ["adresse", "voie", "rue", "localisation", "address", "commune", "ville"]
    for candidat in scores_adresse:
        found = [n for n in field_names if candidat in n.lower()]
        if found:
            col_adresse = found[0]
            break
            
    # 4. M√©tadonn√©es (Titre du dataset, mots-cl√©s)
    metas = dataset_item.get("metas", {}).get("default", {})
    titre_ds = metas.get("title", dataset_item.get("dataset_id"))
    mots_cles = metas.get("keyword", []) 
    if mots_cles is None: mots_cles = [] # S√©curit√© si null
    
    texte_analyse = f"{titre_ds} {' '.join(mots_cles)}"
    icone, couleur = detecter_style(texte_analyse)
    cat = detecter_categorie(texte_analyse)

    return {
        "api_id": dataset_item.get("dataset_id"),
        "titre_dataset": titre_ds,
        "categorie": cat,
        "col_titre": col_titre,
        "col_adresse": col_adresse,
        "col_geo": col_geo,
        "icone": icone,
        "couleur": couleur,
        "infos_sup": field_names[:6] # On garde les 6 premi√®res colonnes pour l'info-bulle
    }

# ==========================================
# 2. CONFIGURATION API & FONCTIONS BACKEND
# ==========================================

VILLES_CONFIG = {
    "Paris üóº": {
        "api_url": "https://opendata.paris.fr/api/explore/v2.1",
        "coords": [48.8566, 2.3522],
        "zoom": 12
    },
    "Rennes üèÅ": {
        "api_url": "https://data.rennesmetropole.fr/api/explore/v2.1",
        "coords": [48.1172, -1.6777],
        "zoom": 13
    },
    "Nantes üêò": {
        "api_url": "https://data.nantesmetropole.fr/api/explore/v2.1",
        "coords": [47.2184, -1.5536],
        "zoom": 13
    },
    "Toulouse üöÄ": {
        "api_url": "https://data.toulouse-metropole.fr/api/explore/v2.1",
        "coords": [43.6047, 1.4442],
        "zoom": 13
    },
     "Strasbourg ü•®": {
        "api_url": "https://data.strasbourg.eu/api/explore/v2.1",
        "coords": [48.5734, 7.7521],
        "zoom": 13
    }
}

# HEADERS : Indispensable pour ne pas √™tre bloqu√© par l'API
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) CityPulse/1.0'
}

@st.cache_data(ttl=3600)
def scanner_catalogue(api_base_url):
    """Scanne le catalogue et g√®re les erreurs API proprement"""
    url = f"{api_base_url}/catalog/datasets"
    
    # Strat√©gie 1 : On essaie de trier par popularit√© (records_count)
    params = {"limit": 60, "order_by": "records_count desc"}
    
    try:
        r = requests.get(url, params=params, headers=HEADERS, timeout=10)
        r.raise_for_status()
        results = r.json().get("results", [])
    
    except Exception:
        # Strat√©gie 2 (Fallback) : Si l'option de tri plante (Erreur 400), on tente sans tri
        try:
            params_simple = {"limit": 60}
            r = requests.get(url, params=params_simple, headers=HEADERS, timeout=10)
            r.raise_for_status()
            results = r.json().get("results", [])
        except Exception as e_final:
            st.error(f"‚ùå Impossible de lire le catalogue de cette ville. ({e_final})")
            return {}

    catalogue_organise = {}
    found_count = 0
    
    for ds in results:
        config = analyser_structure_dataset(ds)
        if config:
            found_count += 1
            cat = config["categorie"]
            if cat not in catalogue_organise:
                catalogue_organise[cat] = {}
            catalogue_organise[cat][config["titre_dataset"]] = config
            
    if found_count == 0 and len(results) > 0:
        st.warning("‚ö†Ô∏è Des donn√©es existent, mais aucune n'a de coordonn√©es GPS exploitables pour une carte.")
            
    return catalogue_organise

@st.cache_data(ttl=600)
def charger_donnees_api(api_base_url, dataset_id):
    """Charge les donn√©es du dataset s√©lectionn√©"""
    url = f"{api_base_url}/catalog/datasets/{dataset_id}/records"
    params = {"limit": 99} # Limite pour fluidit√©
    try:
        r = requests.get(url, params=params, headers=HEADERS, timeout=10)
        r.raise_for_status()
        return r.json().get("results", [])
    except Exception as e:
        st.error(f"Erreur lors du chargement des points : {e}")
        return []

def recuperer_gps(item, col_geo):
    """Extrait lat/lon depuis le JSON, peu importe le format"""
    lat, lon = None, None
    
    # Cas 1 : Colonne GeoJSON/GeoPoint (Standard Opendatasoft)
    if col_geo and col_geo != "AUTO_DETECT_LAT_LON":
        val = item.get(col_geo)
        if isinstance(val, dict):
            lat, lon = val.get("lat"), val.get("lon")
            if not lat and "geometry" in val: # Parfois imbriqu√©
                coords = val.get("geometry", {}).get("coordinates")
                if coords: lon, lat = coords
                
    # Cas 2 : Auto d√©tection dans les colonnes lat/lon
    if not lat:
        keys = item.keys()
        k_lat = next((k for k in keys if k in ["lat", "latitude", "y_wgs84"]), None)
        k_lon = next((k for k in keys if k in ["lon", "long", "longitude", "x_wgs84"]), None)
        if k_lat and k_lon:
            try:
                lat = float(item[k_lat])
                lon = float(item[k_lon])
            except: pass
            
    return lat, lon

# ==========================================
# 3. INTERFACE STREAMLIT
# ==========================================

st.title("üåç City Pulse : Explorateur Dynamique")
st.markdown("Ce tableau de bord **scanne automatiquement** les Open Data des villes pour g√©n√©rer des cartes.")

# --- SIDEBAR ---
with st.sidebar:
    st.header("1. La Ville")
    ville_nom = st.selectbox("Choisir une m√©tropole :", list(VILLES_CONFIG.keys()))
    ville_conf = VILLES_CONFIG[ville_nom]
    
    st.divider()
    
    # SCAN DU CATALOGUE
    with st.spinner(f"üì° Scan des donn√©es de {ville_nom}..."):
        catalogue = scanner_catalogue(ville_conf["api_url"])
    
    if not catalogue:
        st.error("Aucune donn√©e cartographique trouv√©e. Essayez une autre ville ou v√©rifiez l'API.")
        st.stop()
        
    st.header("2. Les Donn√©es")
    
    # Menu Cat√©gorie
    cats_dispo = sorted(list(catalogue.keys()))
    cat_choisie = st.selectbox("Th√©matique :", cats_dispo)
    
    # Menu Dataset
    datasets_dispo = catalogue[cat_choisie]
    dataset_nom = st.selectbox("Jeu de donn√©es :", list(datasets_dispo.keys()))
    
    # Config finale
    config_dataset = datasets_dispo[dataset_nom]
    
    st.success(f"üìç Mode : {config_dataset['col_geo']}")
    st.info(f"üé® Style : {config_dataset['icone']}")

    st.divider()
    activer_filtre = st.toggle("Activer filtre texte")
    txt_filtre = ""
    if activer_filtre:
        txt_filtre = st.text_input("Recherche (ex: Centre, Gare...) :")

# --- MAIN ---

# Chargement
with st.spinner(f"Chargement de : {dataset_nom}..."):
    data = charger_donnees_api(ville_conf["api_url"], config_dataset["api_id"])

# Filtrage local
data_finale = []
if activer_filtre and txt_filtre:
    for d in data:
        if txt_filtre.lower() in str(d).lower():
            data_finale.append(d)
else:
    data_finale = data

st.markdown(f"### {dataset_nom} ({len(data_finale)} lieux)")

# Onglets d'affichage
tab_map, tab_stats, tab_raw = st.tabs(["üó∫Ô∏è Carte Interactive", "üìä Analyse", "üíæ Donn√©es Brutes"])

with tab_map:
    # Initialisation carte
    m = folium.Map(location=ville_conf["coords"], zoom_start=ville_conf["zoom"])
    coords_heat = []
    
    for item in data_finale:
        lat, lon = recuperer_gps(item, config_dataset["col_geo"])
        
        if lat and lon:
            coords_heat.append([lat, lon])
            
            # Popup intelligent
            titre = item.get(config_dataset["col_titre"], "Sans titre")
            adresse = item.get(config_dataset["col_adresse"], "")
            
            html = f"<b>{titre}</b><br><i>{adresse}</i><hr>"
            for col in config_dataset["infos_sup"]:
                val = item.get(col)
                if val: html += f"<span style='font-size:10px; color:grey;'><b>{col}:</b> {str(val)[:40]}</span><br>"
            
            folium.Marker(
                [lat, lon],
                popup=folium.Popup(html, max_width=300),
                icon=folium.Icon(color=config_dataset["couleur"], icon=config_dataset["icone"], prefix="fa")
            ).add_to(m)
            
    if coords_heat:
        st_folium(m, width="100%", height=600)
    else:
        st.warning("Aucune coordonn√©e valide trouv√©e dans ce jeu de donn√©es.")

with tab_stats:
    if len(data_finale) > 0:
        df = pd.DataFrame(data_finale)
        
        col1, col2 = st.columns(2)
        with col1: st.metric("Nombre d'√©l√©ments", len(df))
        with col2: st.metric("Colonnes", len(df.columns))
            
        # Graphique automatique sur les champs texte courts (cat√©gories)
        cat_cols = [c for c in df.columns if df[c].dtype == 'object' and df[c].nunique() < 15]
        if cat_cols:
            st.subheader("Distribution automatique")
            c_g = st.selectbox("Grouper par :", cat_cols)
            chart = alt.Chart(df).mark_bar().encode(
                x=alt.X(c_g, sort='-y', axis=alt.Axis(labelLimit=200)),
                y='count()',
                color=c_g,
                tooltip=[c_g, 'count()']
            ).interactive()
            st.altair_chart(chart, use_container_width=True)
        else:
            st.info("Ce dataset contient des donn√©es trop vari√©es pour g√©n√©rer un graphique automatique.")

with tab_raw:
    st.dataframe(data_finale)
